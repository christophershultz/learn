# Big Data Modeling and Management

The goal of data modeling is to formally explore the nature of data, so you can figure out what type of storage / processing you need. The goal of data mgmt is to figure out what type of infrastructure support you need (e.g. replication, statistical computation, etc.). Figuring these things out will allow you to choose the right system.

# Why Big Data Modeling and Management? 

What does **data management** mean? 

Must-ask questions about a data app: 
* how do we ingest it? 
* where and how do we store it? 
* how can we ensure data quality? 
* what operations do we perform on the data? 
* how can these operations be efficient? 
* how do we scale up data volume, variety, velocity, and access? 
* how do we keep data secure? 

## Data Ingestion

Ingestion is the process of getting the data into the data system. Questions to consider when designing ingestion infrastructure: 

* how many data sources? 
* how large are data items? 
* will the number of data sources grow? 
* rate of data ingestion? 
* what to do with bad data? 
* what to do when data is too little or too much? 

## Data Storage

The goal of storage infrastructure is to store data. We need to think about [1] how much storage to allocate / how much data to store; and [2] scalability: should the storage devices be attached directly to the computers, but less scalable, or connected to a network and thus extensible? 

These questions don't have a simple answer. 

How fast do we need to read/write? Cache memory (L1, L2, L3) is the fastest. Then, in order of speed, we have DRAM, Flash/SSD/USB, HDD, and Tapes, Remote Systems, etc. The faster options are more expensive. 

SSDs have become available and are much faster than spinning hard disks. 

We now have a choice of architecting our storage infrastructure by choosing which components to use for storage and how. This choice ultimately becomes a cost-benefit analysis.

## Data Quality

Data apps should be mindful of data quality.

1. Better quality means better analytics and decisions. Garbage in, garbage out.
2. Quality assurance is required for regulatory compliance.
3. Quality leads to better engagement and interaction with external entities. 

Big data quality issues are handled primarily through the following: data profiling and quality measurement, parsing and standardization, generalized cleansing, matching, monitoring, issue resolution/workflow, and enrichment. 

## Data Operations

There are two broad types of data operations. Those that work on a single data object; and those that work on collections of data objects. 

Every operation should be efficient: fast, minimal memory. Measured by time and space. Should use parallelism if possible. 

## Scalability and Security

Scalability: 
* Vertical Scaling (Scale-Up): adding more processors and RAM, buying a more robust server, etc.
* Many operations perform better with more memory/cores. 
* Maintenance can be difficult/expensive.

Scaling Out: 
* Horizontal Scaling (Scale-Out): adding more, possibly less powerful machines that connect over a network.
* Parallel operations may be slower.
* Easier in practice to add more machines.

The general trend in the big data world is to target the scale-out option. Most data systems operate over a cluster and scale dynamically. 

## Keeping Data Secure
* Data security is a must.
* Increasing the number of machines leads to a security risk.
* Data in transit must be secure.
* Encryption and decryption increase security but make data operations more expensive.

# Real Big Data Management Applications

Consider an energy company (Con Edison). They decided to place smart meters throughout its jurisdictions (4.7M). These measure energy consumption and have a 2-way communication between meter and the gas company. The generate real-time data (1.5billion data points per day). 

The system consumes this and processes it with new outputs every 15-minutes. Ingesting and processing 10.5m data points per 15 minutes. 

Smart Meter Analytics: 
* Consumption Patterns per User: Histograms of Hourly Usage - computed daily and over larger time periods. 
* Thermal Sensitivity: effect of outdoor temperature on the usage of each consumer. 
* Consumption Prediction: daily, weekly usage, economic implications.
* Consumer Grouping: similarity grouping, based on usage patterns, energy saving campaigns for user groups.

The company has only 15 minutes to achieve this. It's not only big, but it needs to be fast. 

---
Gaming Industry Data
* Different sources: finger movement, VR headset, controller, inside game action, etc. 