# Big Data Management

When should we use a Hadoop/YARN style system, and when should we use a standard system? 

What are the advantages of a DBMS vs a file system? 

Storing Data: 
* DB operations were applications in file systems. However, problems arose. Specifically around data redundancy, inconsistency, and isolation. 
* Each task required a separate program. 
* Enforcement of constraints / data integrity: one would have to write this condition as part of an application program code. 
* Atomicity of Updates: all of the changes we need to do must happen altogether as a single unit. They should either fully go through, or not go through at all. 

Advantages of a DBMS: 
* Alleviates the above problems. 
* Include declarative query languages (e.g. SQL) - no more task based programs. We state what we want, without telling it how to do it. 
* Data Independence: apps don't worry about data storage formats / locations. 
* Efficient access through optimization: system automatically finds an efficient way to access data. 
* Data Integrity and Security: DBMS include methods to keep accuracy and consistency of data despite failure: ACID properties of transactions; failure recovery.

The durability property ensures that once a transaction has occurred, it will remain and persist despite system crashes.

* Concurrent Access: many users can simultaneously access data without conflict. 

**Parallel and Distributed DBMS**

Parallel db systems handle big data through distributed processing. Improves performance and often allows for data replication. 

A _distributed_ db system stores data across several sites, each site managed by a DBMS capable of running independently. This is a network of independently running DBMSs. 

Important question: does your data problem actually need these facilities? Usually not. But sometimes, yes. 

**DBMS and MapReduce-Style Systems**

DBMSs started with a different problem focus: efficient storage, transactions, and information retrieval. Query performance is traditionally improved through parallelism. 

MapReduce-style systems offer complex data processing over a cluster of machines. This was originally developed not for storage and retrieval, but complex distributed processing/calculations. In this setting, the number of machines could go up to the thousands. 

MR was built with data mining / ML in mind. The output from one processing stage is often the input to the next. It's difficult to build such multi-stage systems in a traditional DBMS. 

**Shifting Requirements**

* Data Loading: a new bottleneck. Does the app need data sooner than the loading time? 
* Too Much Functionality: the dbms often offers too much functionality. E.g. an application that only looks at the price of an item if you provide it with a product code. No need for joins, table updates, etc. DBMS is overkill. 
* Combined Transactional and Analytical Capabilities: many apps need support for DBMS features and analytical features. E.g. real-time decision support tools. 

There is no single solution for all possible applications. 
* Mixed Solutions: DBMS on HDFS. 
* Relational operations in MR systems like Spark. 
* Streaming input to DBMS. 
* New parallel programming models for computation within DBMS. 

# From DBMS to BDMS

Desired Characteristics of a BDMS: 
1. A flexible, semistructured data model. Can support multiple formats. Flexibility in many ways, including the degree to which schemas are supported in the system. 
2. Support for today's common data types: text, temporal, spatial, etc. 
3. Include a full query language. Expectedly at least the power of SQL. 
4. An efficient parallel query runtime. 
5. Wide range of query sizes. 
6. Continuous data ingestion / streaming.
7. Scale gracefully to manage and query large volumes of data via clusters. 
8. Full data management capabilities.

**ACID and BASE**: 
* ACID properties are hard to maintain in a BDMS. While these properties are still desirable, it might be more practical to relax these conditions.
* BASE relaxes ACID: BA = basic availability (if you make a request, there will be a response in some form); S = soft state (state of the system is likely to change over time); E = eventual consistency (the system will eventually become consistent, once it stops receiving input). 

**CAP Theorem**: There are some theoretical results behind the BASE relaxation of ACID. A distributed computer system cannot simultaneously achieve [1] consistency (all nodes see the same data at any time); [2] availability (every request receives a response); and [3] partition tolerance (the system continues to operate despite arbitrary partitioning due to failures). 

Most systems adhere to BASE, some adhere to ACID.

# REDIS: Enhanced Key-Value Store

Redis is an in-memory data structure store. It's not a full blown DBMS. It can persist data on disks and does so to save its state. Its intended use is to optimally use memory to make common data structures fast for lots of users. It supports strings, hashes, lists, sets, and sorted sets. 

Think of a lookup problem: needs a key-value pair (strings). We provide the key and get back the value. Captchas use this idea of a key value store. The key is the id of the image. The response is the text. 

We could also use the image itself as the key. It can be transformed to a binary string and then used as a key in the Redis framework. Small images like this can be used as string keys. 

You can also have the value be a collection, like a list or ordered set. E.g. Twitter could use this to store timelines. 

**Redis and Scalability**: 

Partitioning and Replication: Redis allows through two forms.
* Range partitioning: E.g. user record number 1-10000 goes to machine 1, user records 10001-20000 goes to machine 2, etc. 
* Hash partitioning: E.g. pick a key of a record, e.g. "abcde". Using a hash function, turn it to a number, e.g. 152. 152 mod 10 is 2 so it goes to machine 2.  

Master-Slave Model Replication
* Clients write to master, master replicates to slaves.
* Clients read from slaves to scale up read performance.
* Slaves are mostly consistent.

# Aerospike: A New KV Store

Aerospike calls itself a distributed noSql database and key-value store. It's built for the performance needs of today's web-scale apps.

Key-Value Store: Fast Path
* Transaction Processing -> Primary Indexing -> Storage on DRAM, Flash/SSD or DISK. 

Operational Queries:
* Query Processing -> Secondary Indexing / In-Database Compute. The secondary index is a non-primary key, but is unique. Each secondary index entry contains references to the records local to the node. 

Management: 
* Integrated Cluster Mgmt, Security, Cross Datacenter Replication, Management Console, and Data Lifecycle / Cache Eviction.

Data Types: 
* Standard scalar, lists, maps, geospatial, large objects.

KV Store Operations: 
* Geospatial queries like point-in-polygon.
* Distance queries.

AQL: a SQL-like Language
* SELECT name, age FROM users.profiles.
* Similar to SQL.

Aerospike ensures ACID, despite being a distributed system. This is accomplished using a number of techniques. 
* Consistency: all copies of a data item are in sync. Uses synchronous write to replicas. Mechanisms to relax immediate consistency. 
* Durability: flash storage, replication management.
* Networking Partitioning Reduced: tigheter cluster control. 

# Semistructured Data: AsterixDB

MongoDB is very popular for semistructured data. AsterixDB is a relatively new system being built by Apache. 

Options for Querying in AsterixDB: 
* AQL is a natively supported query language.
* Hive Queries
* XQuery
* Hadoop MR Jobs
* SQL++ (extends SQL for JSON).

Operating Over a Cluster
* Hyracks: query execution engine for partitioned parallel execution of queries. 

Accessing External Data
* Real-time data from files in a directory path. 
* Real-time data from an external API. 

# Solr: Managing Text

Systems like Solr are typically designed for search problems.

Basic Challenge with Text: 
* Defining a match. E.g. Analyze == Analyse == ANALYZE == Analyze;?? (lexical difference, capitalization, structural punctuations). Barak Obama == Barack H Obama?? (nominal variations). Mom == MOTHER? (synonyms). Dr. == Doctor?? (abbreviations). 

Inverted Index
* Vocabulary: a collection of terms. All terms in a collection fo documents. Multi-word terms, synonym sets, etc. If we have a corpus, we can extract the terms and construct a vocabulary.
* Occurrence: for each term, list of doc id, positions of occurrence, other statistics like tf-idf, etc. 

Solr is an open source enterprise search platform. It provides more than this though. It can take any structured document, even CSV files, and can index each field separately. 

For every field, indexes text, numbers, geography, etc. 

Faceted search: sort of like a conditional search. 

Term highlighting: 

Index-Time Analyzers: 
* Tokenization
* Filters

In short, solr is optimized for handling text data. 

# Relational Data: Vertica (a Columnar DB)

A RDBMS designed to operate on HDFS. In a column store, the data is organized column-wise. A query uses only the columns needed. Usually faster for queries, even for large data. 

Space Efficiency: 
* Column stores keep columns in sorted order. 
* Values in columns can be compressed. 
* Compression saves storage space.

Column Groups: 
* Frequently co-accessed columns behave as mini row-stores within the column store. 
* Update performance slower: internal conversion from row representation to column representation.

Vertica is an "analytical db", which means it offers more statistical functions than a classical DBMS (e.g. window statistics). 

# Distributed R
* High-performance statistical analysis. 
* Master node: schedules tasks and sends code. Worker nodes: maintain data partitions and compute.
* Uses a data structure called dArray or distributed array. 

Workflow: 
* Load data from Vertica/HDFS
* Optionally add data using Idol-on-demand APIs
* Train model using RF in distributed R
* Deploy model to Vertica or as a web service. 